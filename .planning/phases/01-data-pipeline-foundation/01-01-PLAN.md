---
phase: 01-data-pipeline-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/__init__.py
  - backend/app/main.py
  - backend/app/config.py
  - backend/app/database.py
  - backend/app/models/__init__.py
  - backend/app/models/stock.py
  - backend/app/models/score_snapshot.py
  - backend/requirements.txt
  - backend/alembic.ini
  - backend/alembic/env.py
  - backend/.env.example
autonomous: true
requirements:
  - DATA-02

must_haves:
  truths:
    - "SQLite database initializes on app startup without errors"
    - "Stock and ScoreSnapshot models map to correct schema columns"
    - "Alembic env.py connects to the async SQLite database"
    - "All imports resolve (no circular dependencies)"
  artifacts:
    - path: "backend/app/database.py"
      provides: "Async SQLAlchemy engine + session factory"
      exports: ["engine", "async_session_maker", "Base", "get_db"]
    - path: "backend/app/models/stock.py"
      provides: "Stock and Domain ORM models"
      contains: "class Stock"
    - path: "backend/app/models/score_snapshot.py"
      provides: "ScoreSnapshot ORM model with fetched_at index"
      contains: "class ScoreSnapshot"
    - path: "backend/app/main.py"
      provides: "FastAPI app with lifespan stub"
      contains: "FastAPI(lifespan=lifespan)"
    - path: "backend/requirements.txt"
      provides: "Pinned dependency list"
      contains: "apscheduler>=3.10,<4.0"
  key_links:
    - from: "backend/app/models/stock.py"
      to: "backend/app/database.py"
      via: "imports Base from database"
      pattern: "from.*database.*import.*Base"
    - from: "backend/app/main.py"
      to: "backend/app/database.py"
      via: "create_all in lifespan"
      pattern: "create_all|Base.metadata"
    - from: "backend/alembic/env.py"
      to: "backend/app/database.py"
      via: "imports Base.metadata for autogenerate"
      pattern: "from.*database.*import"
---

<objective>
Set up the backend project scaffold and SQLAlchemy models — the foundation every other plan in this phase depends on.

Purpose: Establishes the async SQLite database layer, ORM models, and FastAPI app skeleton that data fetching, scheduling, and routing will build on.
Output: Runnable FastAPI skeleton with DB models and Alembic configured.
</objective>

<execution_context>
@C:/Users/Yarin David/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Yarin David/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend scaffold — requirements, config, FastAPI skeleton</name>
  <files>
    backend/requirements.txt
    backend/.env.example
    backend/app/__init__.py
    backend/app/config.py
    backend/app/main.py
  </files>
  <action>
Create the backend/ directory tree. All files below go inside backend/.

**backend/requirements.txt** — pin these exact version constraints:
```
fastapi>=0.115,<1.0
uvicorn[standard]>=0.29
yfinance>=1.0
pandas>=2.2
sqlalchemy>=2.0
aiosqlite>=0.20
alembic>=1.13
apscheduler>=3.10,<4.0
python-dotenv>=1.0
pytest>=8.0
pytest-asyncio>=0.23
httpx>=0.27
```

**backend/.env.example**:
```
DATABASE_URL=sqlite+aiosqlite:///./stocks.db
FETCH_INTERVAL_MINUTES=5
```

**backend/app/__init__.py** — empty file.

**backend/app/config.py** — use pydantic-settings BaseSettings:
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    database_url: str = "sqlite+aiosqlite:///./stocks.db"
    fetch_interval_minutes: int = 5

    class Config:
        env_file = ".env"

settings = Settings()
```
Note: pydantic-settings is a separate package in pydantic v2 — add `pydantic-settings>=2.0` to requirements.txt.

**backend/app/main.py** — FastAPI app with lifespan context manager (NOT @app.on_event which is deprecated):
```python
from contextlib import asynccontextmanager
from fastapi import FastAPI
from .database import engine, Base

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Create tables on startup (Alembic handles migrations in production)
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    yield
    await engine.dispose()

app = FastAPI(title="Smart Stock Ranker", lifespan=lifespan)

@app.get("/")
async def root():
    return {"status": "ok"}
```
  </action>
  <verify>
From backend/ directory: `python -c "from app.main import app; print('OK')"` should print OK without import errors.
  </verify>
  <done>FastAPI app imports cleanly; requirements.txt includes all listed packages with apscheduler pinned &lt;4.0.</done>
</task>

<task type="auto">
  <name>Task 2: SQLAlchemy models (Stock, Domain, ScoreSnapshot) + database.py + Alembic init</name>
  <files>
    backend/app/database.py
    backend/app/models/__init__.py
    backend/app/models/stock.py
    backend/app/models/score_snapshot.py
    backend/alembic.ini
    backend/alembic/env.py
  </files>
  <action>
**backend/app/database.py** — async engine with WAL mode + session factory:
```python
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy.orm import DeclarativeBase
from sqlalchemy import event
from .config import settings

engine = create_async_engine(settings.database_url, echo=False)

# Enable WAL mode for SQLite (better concurrent read performance)
@event.listens_for(engine.sync_engine, "connect")
def set_wal_mode(dbapi_conn, connection_record):
    dbapi_conn.execute("PRAGMA journal_mode=WAL")

async_session_maker = async_sessionmaker(engine, expire_on_commit=False)
Base = DeclarativeBase.__class_getitem__  # placeholder, overridden below

class Base(DeclarativeBase):
    pass

async def get_db() -> AsyncSession:
    async with async_session_maker() as session:
        yield session
```
Note: `class Base(DeclarativeBase): pass` is the correct SQLAlchemy 2.0 pattern. Remove the placeholder line above it. Final database.py should have: engine, WAL listener, async_session_maker, Base, get_db.

**backend/app/models/__init__.py**:
```python
from .stock import Stock, Domain
from .score_snapshot import ScoreSnapshot
```

**backend/app/models/stock.py** — Stock and Domain models using SQLAlchemy 2.0 Mapped syntax:
```python
from sqlalchemy import String, Float, DateTime, ForeignKey
from sqlalchemy.orm import Mapped, mapped_column, relationship
from datetime import datetime
from ..database import Base

class Domain(Base):
    __tablename__ = "domains"
    id: Mapped[int] = mapped_column(primary_key=True)
    name: Mapped[str] = mapped_column(String(50), unique=True, nullable=False)
    stocks: Mapped[list["Stock"]] = relationship(back_populates="domain")

class Stock(Base):
    __tablename__ = "stocks"
    ticker: Mapped[str] = mapped_column(String(10), primary_key=True)
    name: Mapped[str] = mapped_column(String(100), nullable=False)
    domain_id: Mapped[int] = mapped_column(ForeignKey("domains.id"), nullable=False)
    domain: Mapped["Domain"] = relationship(back_populates="stocks")
    last_updated: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
```

**backend/app/models/score_snapshot.py** — ScoreSnapshot stores each fetch result:
```python
from sqlalchemy import String, Float, DateTime, Integer
from sqlalchemy.orm import Mapped, mapped_column
from datetime import datetime
from ..database import Base

class ScoreSnapshot(Base):
    __tablename__ = "score_snapshots"
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)
    ticker: Mapped[str] = mapped_column(String(10), index=True, nullable=False)
    close_price: Mapped[float] = mapped_column(Float, nullable=False)
    volume: Mapped[float] = mapped_column(Float, nullable=False)
    fetched_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), index=True, nullable=False)
```

**Alembic init** — run from backend/ directory:
```bash
alembic init alembic
```
Then update **backend/alembic/env.py** to import Base and use the async engine. Key changes to the generated env.py:
- Add imports: `from app.database import Base; from app import models`
- Set `target_metadata = Base.metadata`
- For `run_migrations_online()`, use async runner:
```python
import asyncio
from sqlalchemy.ext.asyncio import async_engine_from_config

def run_migrations_online() -> None:
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
    )
    async def run(connectable):
        async with connectable.connect() as connection:
            await connection.run_sync(do_run_migrations)
        await connectable.dispose()
    asyncio.run(run(connectable))
```
Update alembic.ini sqlalchemy.url to `sqlite+aiosqlite:///./stocks.db`.

Also seed the Domain and Stock data into the DB at startup. Add a `seed_db()` async function in `backend/app/database.py` (or a new `backend/app/seed.py`) that inserts the Phase 1 test tickers if they don't exist:
- Domains: "AI/Tech", "EV", "Finance"
- Stocks: AAPL, MSFT, NVDA, AMD, GOOGL → AI/Tech; TSLA, RIVN → EV; JPM, GS → Finance
- Call seed_db() from the lifespan in main.py after create_all.
  </action>
  <verify>
From backend/ directory:
1. `python -c "from app.models import Stock, Domain, ScoreSnapshot; print('models OK')"` — no import errors.
2. `python -c "import asyncio; from app.main import app; print('app OK')"` — no errors.
3. `alembic check` — should report no pending migrations (tables exist via create_all).
  </verify>
  <done>All three models import cleanly. Alembic env.py points to async engine with Base.metadata. Seed tickers present in models/__init__.py. Database initializes on first run.</done>
</task>

</tasks>

<verification>
From backend/ directory run:
```bash
pip install -r requirements.txt
python -c "from app.main import app; from app.models import Stock, Domain, ScoreSnapshot; print('All imports OK')"
```
Both commands complete without errors.
</verification>

<success_criteria>
- backend/requirements.txt exists with apscheduler pinned >=3.10,<4.0
- FastAPI app starts (uvicorn app.main:app) without errors
- All three SQLAlchemy models (Stock, Domain, ScoreSnapshot) import cleanly
- Alembic is initialized and env.py targets async engine
- Seed tickers (9 stocks across 3 domains) inserted on first startup
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline-foundation/01-01-SUMMARY.md` using the summary template.
</output>
