---
phase: 03-api-dashboard
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models/ranking_result.py
  - backend/app/seed.py
  - backend/app/services/data_fetcher.py
  - backend/app/scheduler.py
  - backend/alembic/versions/add_ranking_results.py
autonomous: true
requirements: [DOM-01, DOM-02]

must_haves:
  truths:
    - "ranking_results table exists in DB with all factor columns"
    - "fetch_cycle() reads domains/tickers from DB (no hardcoded DOMAIN_GROUPS)"
    - "fetch_cycle() persists RankingResult rows after rank_domain() returns"
    - "12 domains with 4-5 tickers each are seeded in DB"
  artifacts:
    - path: "backend/app/models/ranking_result.py"
      provides: "RankingResult SQLAlchemy model"
      contains: "class RankingResult"
    - path: "backend/alembic/versions/add_ranking_results.py"
      provides: "Alembic migration for ranking_results table"
  key_links:
    - from: "backend/app/scheduler.py fetch_cycle()"
      to: "backend/app/models/ranking_result.py"
      via: "session.add(RankingResult(...))"
      pattern: "RankingResult"
    - from: "backend/app/scheduler.py fetch_cycle()"
      to: "backend/app/models/stock.py Domain"
      via: "DB query replacing DOMAIN_GROUPS"
      pattern: "selectinload.*Domain.stocks"
---

<objective>
Persist ranking results to DB and expand seed data to 12 domains.

Purpose: Routes in plan 02 need data in ranking_results table. fetch_cycle() currently logs rankings but never persists them.
Output: RankingResult model, Alembic migration, expanded seed (12 domains), updated fetch_cycle() that reads domains from DB and writes RankingResult rows.
</objective>

<execution_context>
@C:/Users/Yarin David/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Yarin David/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@backend/app/models/stock.py
@backend/app/models/score_snapshot.py
@backend/app/scheduler.py
@backend/app/seed.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RankingResult model + Alembic migration</name>
  <files>backend/app/models/ranking_result.py</files>
  <action>
Create `backend/app/models/ranking_result.py` with RankingResult model (SQLAlchemy 2.0 Mapped[T] syntax, same pattern as score_snapshot.py):

```python
from datetime import datetime
from sqlalchemy import String, Float, Integer, DateTime
from sqlalchemy.orm import Mapped, mapped_column
from ..database import Base

class RankingResult(Base):
    __tablename__ = "ranking_results"
    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)
    ticker: Mapped[str] = mapped_column(String(10), index=True, nullable=False)
    domain: Mapped[str] = mapped_column(String(50), index=True, nullable=False)
    composite_score: Mapped[float] = mapped_column(Float, nullable=False)
    rank: Mapped[int] = mapped_column(Integer, nullable=False)
    momentum: Mapped[float | None] = mapped_column(Float, nullable=True)
    volume_change: Mapped[float | None] = mapped_column(Float, nullable=True)
    volatility: Mapped[float | None] = mapped_column(Float, nullable=True)
    relative_strength: Mapped[float | None] = mapped_column(Float, nullable=True)
    financial_ratio: Mapped[float | None] = mapped_column(Float, nullable=True)
    computed_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), index=True, nullable=False)
```

Then generate Alembic migration from `backend/` dir:
```bash
cd backend && alembic revision --autogenerate -m "add_ranking_results"
```
Then apply:
```bash
cd backend && alembic upgrade head
```
  </action>
  <verify>
```bash
cd backend && python -c "from app.models.ranking_result import RankingResult; print('ok')"
cd backend && alembic current
```
alembic current shows head.
  </verify>
  <done>RankingResult importable, ranking_results table exists in Supabase DB.</done>
</task>

<task type="auto">
  <name>Task 2: Expand seed + update fetch_cycle()</name>
  <files>backend/app/seed.py, backend/app/scheduler.py, backend/app/services/data_fetcher.py</files>
  <action>
**seed.py** — Replace SEED_DATA with 12 domains (keep AI/Tech, EV, Finance; add 9 more). Use select-then-insert pattern (already idempotent). Domains and representative tickers:

```python
SEED_DATA = {
    "AI/Tech":          [("AAPL","Apple Inc."),("MSFT","Microsoft Corp."),("NVDA","NVIDIA Corp."),("AMD","Advanced Micro Devices"),("GOOGL","Alphabet Inc.")],
    "EV":               [("TSLA","Tesla Inc."),("RIVN","Rivian Automotive"),("NIO","NIO Inc."),("LCID","Lucid Group")],
    "Finance":          [("JPM","JPMorgan Chase"),("GS","Goldman Sachs"),("BAC","Bank of America"),("MS","Morgan Stanley")],
    "Healthcare":       [("JNJ","Johnson & Johnson"),("UNH","UnitedHealth Group"),("PFE","Pfizer Inc."),("ABBV","AbbVie Inc.")],
    "Energy":           [("XOM","Exxon Mobil"),("CVX","Chevron Corp."),("COP","ConocoPhillips"),("SLB","SLB (Schlumberger)")],
    "Consumer":         [("AMZN","Amazon.com Inc."),("WMT","Walmart Inc."),("HD","Home Depot"),("MCD","McDonald's Corp.")],
    "Semiconductors":   [("TSM","Taiwan Semiconductor"),("INTC","Intel Corp."),("QCOM","Qualcomm Inc."),("AVGO","Broadcom Inc.")],
    "Defense":          [("LMT","Lockheed Martin"),("RTX","RTX Corp."),("NOC","Northrop Grumman"),("GD","General Dynamics")],
    "Crypto/Fintech":   [("COIN","Coinbase Global"),("PYPL","PayPal Holdings"),("SQ","Block Inc."),("HOOD","Robinhood Markets")],
    "Industrials":      [("CAT","Caterpillar Inc."),("DE","Deere & Company"),("HON","Honeywell Intl."),("UPS","United Parcel Service")],
    "Media/Streaming":  [("NFLX","Netflix Inc."),("DIS","Walt Disney Co."),("SPOT","Spotify Technology"),("PARA","Paramount Global")],
    "Real Estate":      [("AMT","American Tower"),("PLD","Prologis Inc."),("EQIX","Equinix Inc."),("SPG","Simon Property Group")],
}
```

**data_fetcher.py** — Update SEED_TICKERS to match (flat list of all tickers from new SEED_DATA).

**scheduler.py** — Replace the hardcoded `DOMAIN_GROUPS` block and logging-only loop with:
1. DB query to load domains + stocks using sync session (already have `_sync_engine`):
```python
from sqlalchemy.orm import selectinload
from .models.ranking_result import RankingResult
from .models.stock import Domain

# Inside fetch_cycle(), after persisting ScoreSnapshot rows:
with Session(_sync_engine) as session:
    domain_rows = session.execute(
        select(Domain).options(selectinload(Domain.stocks))
    ).scalars().all()
    domain_groups = {d.name: [s.ticker for s in d.stocks] for d in domain_rows}
```
2. Replace DOMAIN_GROUPS with domain_groups from DB query.
3. After rank_domain() returns results, persist RankingResult rows (in same session, same with-block):
```python
    now_computed = datetime.now(timezone.utc)
    for domain_name, tickers in domain_groups.items():
        # ... compute factors, call rank_domain() ...
        results = rank_domain(stocks_data)
        for ticker, score in results.items():
            session.add(RankingResult(
                ticker=ticker,
                domain=domain_name,
                composite_score=score.composite_score,
                rank=score.rank,
                momentum=score.factors.momentum,
                volume_change=score.factors.volume_change,
                volatility=score.factors.volatility,
                relative_strength=score.factors.relative_strength,
                financial_ratio=score.factors.financial_ratio,
                computed_at=now_computed,
            ))
    session.commit()
```
Note: Access factor breakdown via `score.factors` (StockScore dataclass from ranking_engine.py). Check actual field names in `backend/app/services/ranking_engine.py` before writing.

Keep the second yf.download() for 30d history as-is (don't refactor it). Move it inside the new session block or keep it before — just ensure domain_groups is populated from DB before building all_tickers list.
  </action>
  <verify>
```bash
cd backend && python -c "from app.seed import SEED_DATA; print(len(SEED_DATA), 'domains')"
cd backend && python -c "from app.scheduler import fetch_cycle; print('fetch_cycle importable')"
```
Seed data shows 12 domains. Start the server and check logs after first fetch_cycle() run — should log "persisted N ranking results".
  </verify>
  <done>12 domains seeded. fetch_cycle() reads domains from DB and writes RankingResult rows (not just logs).</done>
</task>

</tasks>

<verification>
```bash
cd backend && python -c "from app.models.ranking_result import RankingResult; print('model ok')"
cd backend && python -c "from app.seed import SEED_DATA; assert len(SEED_DATA) == 12"
cd backend && alembic current  # shows head
```
</verification>

<success_criteria>
- ranking_results table in Supabase with all columns
- 12 domains + their tickers in DB after seed
- fetch_cycle() no longer has hardcoded DOMAIN_GROUPS
- fetch_cycle() writes RankingResult rows on every successful run
</success_criteria>

<output>
After completion, create `.planning/phases/03-api-dashboard/03-01-SUMMARY.md`
</output>
