---
phase: 02-ranking-algorithm
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - backend/app/services/data_fetcher.py
  - backend/app/scheduler.py
autonomous: true
requirements: [ALGO-01, ALGO-02, ALGO-03, ALGO-04, ALGO-05, ALGO-06]

must_haves:
  truths:
    - "fetch_all_stocks() downloads 30 days of history (not 2d) so momentum and volatility have enough data"
    - "compute_factors_for_ticker() returns a dict with all 5 factor keys (raw values, None when unavailable)"
    - "volatility raw value is pre-inverted (multiplied by -1) before being passed to rank_domain()"
    - "relative_strength is computed as ticker's 5-day return minus median of all domain tickers' 5-day returns"
    - "financial_ratio uses ticker.info.get('trailingPE') — never ticker.info['trailingPE']"
    - "fetch_cycle() calls compute_factors_for_ticker() for each ticker then rank_domain() per domain"
    - "rank_domain() results are logged (ticker, score, rank) per domain at INFO level"
  artifacts:
    - path: "backend/app/services/data_fetcher.py"
      provides: "Extended fetcher: period=30d + compute_factors_for_ticker()"
      exports: [fetch_all_stocks, compute_factors_for_ticker, validate_ticker_data, SEED_TICKERS]
    - path: "backend/app/scheduler.py"
      provides: "fetch_cycle() wired to factor computation + rank_domain() per domain"
  key_links:
    - from: "backend/app/scheduler.py"
      to: "backend/app/services/ranking_engine.py"
      via: "from app.services.ranking_engine import rank_domain"
      pattern: "rank_domain"
    - from: "backend/app/scheduler.py"
      to: "backend/app/services/data_fetcher.py"
      via: "from app.services.data_fetcher import compute_factors_for_ticker"
      pattern: "compute_factors_for_ticker"
    - from: "backend/app/services/data_fetcher.py"
      to: "yfinance"
      via: "yf.download(period='30d') and yf.Ticker(ticker).info.get('trailingPE')"
      pattern: "period=\"30d\""
---

<objective>
Extend the data fetcher to compute all 5 raw factor values per ticker, then wire the ranking engine into the scheduler so scores are computed on every fetch cycle.

Purpose: Connects the pure ranking engine (Plan 01) to real yfinance data — completing the pipeline from market data to ranked scores.
Output: data_fetcher.py with factor computation, scheduler.py calling rank_domain() per domain on every cycle.
</objective>

<execution_context>
@C:/Users/Yarin David/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Yarin David/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@backend/app/services/data_fetcher.py
@backend/app/scheduler.py
@.planning/phases/02-ranking-algorithm/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend data_fetcher.py — period=30d + compute_factors_for_ticker()</name>
  <files>backend/app/services/data_fetcher.py</files>
  <action>
    ## Change 1: Extend period from "2d" to "30d"

    In fetch_all_stocks(), change the yf.download() call:
    - Before: period="2d"
    - After: period="30d"

    The return signature stays the same: {ticker: {"close_price": float, "volume": float}} — still uses the latest row for close/volume. The extended history is needed by compute_factors_for_ticker().

    ## Change 2: Add compute_factors_for_ticker()

    Add a new function below fetch_all_stocks():

    ```python
    def compute_factors_for_ticker(
        ticker: str,
        history: "pd.DataFrame",          # full multi-ticker yf.download() result (30d)
        all_histories: "pd.DataFrame",     # same object — used for relative_strength
        domain_tickers: list[str],         # all tickers in this stock's domain
    ) -> dict[str, float | None]:
    ```

    The function extracts factor values from the downloaded DataFrame. Use try/except around each factor independently so one failure does not block others.

    ### Factor 1: momentum
    ```python
    close_series = history["Close"][ticker].dropna()
    momentum = float(close_series.pct_change(5).iloc[-1])  # 5-day return
    # None if fewer than 6 rows or result is NaN
    ```

    ### Factor 2: volume_change
    ```python
    vol_series = history["Volume"][ticker].dropna()
    volume_change = float(vol_series.pct_change(5).iloc[-1])  # 5-day % change
    # None if fewer than 6 rows or result is NaN
    ```

    ### Factor 3: volatility (INVERT BEFORE RETURNING)
    ```python
    close_series = history["Close"][ticker].dropna()
    log_returns = np.log(close_series / close_series.shift(1)).dropna()
    vol_raw = float(log_returns.rolling(21).std(ddof=0).iloc[-1])
    volatility = -1.0 * vol_raw   # INVERT: lower std = less risky = higher score
    # None if fewer than 22 rows or result is NaN
    ```

    ### Factor 4: relative_strength
    ```python
    # Stock's 5-day return minus median of domain peers' 5-day returns
    stock_return = float(history["Close"][ticker].pct_change(5).iloc[-1])
    peer_returns = []
    for peer in domain_tickers:
        try:
            r = float(all_histories["Close"][peer].pct_change(5).iloc[-1])
            if not math.isnan(r):
                peer_returns.append(r)
        except Exception:
            pass
    if peer_returns:
        median_return = float(np.median(peer_returns))
        relative_strength = stock_return - median_return
    else:
        relative_strength = None
    ```

    ### Factor 5: financial_ratio (INVERT BEFORE RETURNING)
    ```python
    # Use .get() — NEVER dict-style access. trailingPE is None by default.
    info = yf.Ticker(ticker).info
    pe = info.get("trailingPE")
    financial_ratio = (-1.0 * float(pe)) if pe is not None else None
    # INVERT: lower PE = cheaper stock = higher score
    ```

    ### Return structure
    ```python
    return {
        "momentum": momentum,
        "volume_change": volume_change,
        "volatility": volatility,
        "relative_strength": relative_strength,
        "financial_ratio": financial_ratio,
    }
    ```

    Handle any exception in the entire function body with a broad try/except that returns all-None dict and logs a warning. Add `import numpy as np` at the top (numpy is available via pandas dependency).

    Check: math is already imported. Add pandas type annotation as string literal to avoid circular import.
  </action>
  <verify>
    cd backend && python -c "
    from app.services.data_fetcher import compute_factors_for_ticker, fetch_all_stocks
    print('imports OK')
    # Verify period change
    import inspect, app.services.data_fetcher as df
    src = inspect.getsource(df.fetch_all_stocks)
    assert '30d' in src, 'period still 2d!'
    print('period=30d confirmed')
    "
  </verify>
  <done>
    - fetch_all_stocks() uses period="30d"
    - compute_factors_for_ticker() importable, returns dict with keys: momentum, volume_change, volatility, relative_strength, financial_ratio
    - Each factor independently wrapped in try/except returning None on failure
    - volatility and financial_ratio are pre-inverted (multiplied by -1.0) before being returned
    - financial_ratio uses .get("trailingPE") — never ["trailingPE"]
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire rank_domain() into fetch_cycle() in scheduler.py</name>
  <files>backend/app/scheduler.py</files>
  <action>
    ## Overview

    Read the current scheduler.py to understand fetch_cycle(). It currently fetches prices and upserts ScoreSnapshot rows. Extend it to also compute factors and call rank_domain() per domain.

    ## Imports to add at top of scheduler.py

    ```python
    import numpy as np  # already available; needed for compute_factors_for_ticker
    import yfinance as yf
    from app.services.data_fetcher import compute_factors_for_ticker
    from app.services.ranking_engine import rank_domain
    ```

    NOTE: fetch_all_stocks already does the yf.download() call. For factor computation we need to pass the same raw DataFrame. Refactor fetch_all_stocks() OR do a second download in fetch_cycle() — choose the simpler path: fetch_cycle() calls yf.download() directly for factor computation (period=30d) then passes the raw DataFrame to compute_factors_for_ticker() for each ticker.

    ## fetch_cycle() additions

    After the existing price fetch and upsert logic (do NOT remove existing upsert), add:

    ```python
    # --- Factor computation and ranking ---
    # Domain groupings mirror SEED_TICKERS — hardcoded for Phase 2
    # Phase 3 will read these from the DB
    DOMAIN_GROUPS = {
        "AI/Tech": ["AAPL", "MSFT", "NVDA", "AMD", "GOOGL"],
        "EV":      ["TSLA", "RIVN"],
        "Finance": ["JPM", "GS"],
    }

    # Download 30d history for factor computation (single batch call)
    try:
        all_tickers = [t for group in DOMAIN_GROUPS.values() for t in group]
        history = yf.download(
            all_tickers,
            period="30d",
            interval="1d",
            auto_adjust=True,
            progress=False,
            threads=True,
        )
    except Exception as exc:
        logger.error("Factor history download failed: %s", exc)
        return

    for domain_name, tickers in DOMAIN_GROUPS.items():
        stocks_data: dict[str, dict] = {}
        for ticker in tickers:
            factors = compute_factors_for_ticker(
                ticker=ticker,
                history=history,
                all_histories=history,
                domain_tickers=tickers,
            )
            stocks_data[ticker] = factors

        results = rank_domain(stocks_data)
        for ticker, score in results.items():
            logger.info(
                "Domain=%s ticker=%s score=%.1f rank=%d",
                domain_name, ticker, score.composite_score, score.rank,
            )
    ```

    IMPORTANT: Add this block AFTER the existing price/upsert logic, not instead of it. The existing ScoreSnapshot upsert (from Phase 1) must continue to work.

    The DOMAIN_GROUPS dict is defined inside fetch_cycle() for now (not at module level) — Phase 3 will replace this with a DB query.
  </action>
  <verify>
    # Start the server and check logs after one fetch cycle
    cd backend && python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
    sleep 35
    # Trigger a manual fetch cycle by checking logs, or wait for scheduler (5-min interval)
    # Minimum check: imports resolve without error
    python -c "
    from app.scheduler import fetch_cycle
    print('scheduler imports OK')
    from app.services.ranking_engine import rank_domain
    from app.services.data_fetcher import compute_factors_for_ticker
    print('all imports chain OK')
    "
    # Full verify: run server and confirm no ImportError or AttributeError in startup logs
  </verify>
  <done>
    - scheduler.py imports rank_domain and compute_factors_for_ticker without error
    - fetch_cycle() contains DOMAIN_GROUPS dict and the ranking block
    - Existing ScoreSnapshot upsert logic is preserved (not removed)
    - When fetch_cycle() runs, logger.info lines appear for each ticker with score and rank
    - Server starts cleanly: uvicorn logs no ImportError or TypeError
  </done>
</task>

</tasks>

<verification>
## Import chain verification
cd backend && python -c "
from app.services.ranking_engine import rank_domain, StockScore, FactorScore
from app.services.data_fetcher import compute_factors_for_ticker, fetch_all_stocks
from app.scheduler import fetch_cycle
print('Full import chain: OK')
"

## Period change verification
cd backend && python -c "
import inspect, app.services.data_fetcher as df
src = inspect.getsource(df.fetch_all_stocks)
assert '30d' in src
print('period=30d: OK')
"

## Inversion verification
cd backend && python -c "
import inspect, app.services.data_fetcher as df
src = inspect.getsource(df.compute_factors_for_ticker)
assert '-1.0' in src or '* -1' in src
print('inversion present: OK')
"

## Tests still pass
cd backend && python -m pytest tests/test_ranking_engine.py -v
</verification>

<success_criteria>
- data_fetcher.py: period="30d", compute_factors_for_ticker() returns 5-factor dict with pre-inverted volatility and financial_ratio
- scheduler.py: fetch_cycle() calls rank_domain() per domain and logs results at INFO level
- Full import chain resolves without error
- Existing ScoreSnapshot upsert is unchanged
- pytest tests/test_ranking_engine.py still GREEN (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/02-ranking-algorithm/02-02-SUMMARY.md`
</output>
